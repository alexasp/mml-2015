%===================================== CHAP 4 =================================

\chapter{Experiment}

Introduce the experiment

\subsection{Dataset}
This section will introduce the dataset(s) used. What features it contains, what we try to learn/classify, and why we chose to use it.
The Spambase Dataset \cite{spambase1999data} was used as a baseline training set. This dataset is publicly available from the UCI machine learning directory, and contains 57 input attributes of continuous format which serves as input features for spam detection and 1 target attribute in discrete format which represents the class.

We chose this dataset as it is a popular dataset to analyze the performance of binary classifiers, so that we could compare the results of other logistic regression classifiers against our own. While this dataset might not seem like the ideal choice for testing a differentially private classifier due to its lack of personal information, we argue that it still fits well for the purpose of demonstration. In a spam-classifying system based on our distributed model, a logistic regression model can be built by training it locally in each user's personal mail folder and then aggregated into an ensemble. That way you can build a diverse spam-classifier without the users having to give up their personal email to a centralized database.     

Used normalization to scale the data to 0-1 range, this is due to the proof in Chaudli paper which states the assumption $|X_i|< 1$. Based on the formula
\begin{eqnarray}
	X_{norm} = \frac{X-X_{min}}{X_{max} - X_{min}}
\end{eqnarray}


\section{Algorithm}
This section explain the logistic regression algorithm, how it is commonly used, and what modifications are needed when used in a distributed setting. Explanation on how it is used in a differentially private manner is explained in the architecture section. 


\subsection{Distribution}
Introduce notion of distributed machine learning. 

Why did we choose to perform distributed learning?

How does it fit with the notion of differential privacy?

Can we guarantee differential privacy while doing it distributed

Record-based differential privacy. Does it work?

\todo[inline]{This section should maybe go somewhere else, but where?}

\section{Architecture}

In this section we will describe the architecture of Archipelago, our distributed machine learning system. 
Using notions borrowed from PINQ, we designed a distributed system using the JADE framework. Consists of explanation of peers, NoisyQueryable, DataLoader

 \missingfigure[figwidth=6cm]{Figure explaining our framework}

\subsection{Communication}
\subsubsection{Peer}
How is each peer set up, and what behaviors do they implement? 
How do they update then propagate the model being learned.
How do they know when to stop?
\subsubsection{messaging}
How do the peers communicate with each other?
What does a message look like?
What is the PeerGraph?
What controls the messages and determines where they should go?

\subsection{Learning}
How is a logistic model implemented in our framework?

How is a model created and passed around the network?
Each Peer creates a logistic model based on their local data. They then form groups by calling the GroupFormingManager which assigns a group of peers together. This groups creates an aggregated model based on their own local ones. Here we simulate a Homomorphic Encryption scheme which assigns noise by secret sharing. 


How does the ensemble learning choose the best model?
What kind of performance metrics are used?
Mean classification error and Confusion Matrix.

\subsection{Privacy}
How does our framework guarantee differential privacy?
Based on the paper by 

\subsection{Experiment}
How are the experiments set up?
Explain the testing scheme.

Jade is re-run with while changing the initial parameters for the amount of peers, and the size of the groups they form. This test if performed over 10 iterations, while the mean classification error is recorded for each iteration. Each peer also create a confusion matrix with their classification results, and the peer with the best classification accuracy is saved and used to create a ROC-curve. 

Automatic testing scheme - Jade is configured so that it resets the main container after each experiment, and then re-run with new parameter configurations. 

Implemented 10-fold cross validation. This way we can tune the parameters and not be scared of our model overfitting on the test data. our initial solution was to use a single training and a single test set. This way we tuned the parameters so that they would give the best possible accuracy on the test set, which is not how the system should behave in the real world. 



\cleardoublepage