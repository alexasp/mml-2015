% !TeX spellcheck = en_US
\clearpage
\pagenumbering{roman} 				
\setcounter{page}{1}

\pagestyle{fancy}
\fancyhf{}
\renewcommand{\chaptermark}[1]{\markboth{\chaptername\ \thechapter.\ #1}{}}
\renewcommand{\sectionmark}[1]{\markright{\thesection\ #1}}
\renewcommand{\headrulewidth}{0.1ex}
\renewcommand{\footrulewidth}{0.1ex}
\fancyfoot[LE,RO]{\thepage}
\fancypagestyle{plain}{\fancyhf{}\fancyfoot[LE,RO]{\thepage}\renewcommand{\headrulewidth}{0ex}}

\section*{\Huge Abstract}
\addcontentsline{toc}{chapter}{Summary}	
$\\[0.5cm]$

\noindent 
In the field of privacy-preserving data mining the common practice has been to gather data from the users, centralize it in a single database, and employ various anonymization techniques to protect the personally identifiable information contained within the data. Both theoretical analyses and real-world examples of data breaches have proven that these methods have severe shortcomings in protecting an individual's privacy. A breakthrough may have been achieved in 2006 when a method called differential privacy was proposed as a mathematical guarantee for the privacy of each record in a data set. Since then, an avenue of research has been to make this concept work in a distributed setting.

In this thesis we propose a decentralized framework that allows users to perform classification after aggregating their locally trained models in a privacy-preserving manner. We describe a series of experiments on the tuning of each major parameter involved, and show the effects of these on the privacy-utility trade-off. We also compare our classification performance to other cases in the literature and show how we achieve competitive performance. 

Based on our results, we have produced a set of criteria for applying differential privacy to a machine learning application, as well as two business sectors where we see potential for a successful system. We hope that our research will pave the way for distributed applications where users maintain control of their own data, and use it for learning without giving up their privacy.   	

\cleardoublepage

\section*{\Huge Sammendrag}
$\\[0.5cm]$

\noindent 
Innenfor forskningsfeltet kalt \textit{privacy-preserving data mining} har det lenge v{\ae}rt vanlig praksis {\aa} samle data fra en mengde brukere, sentralisere den i en stor database, og s{\aa} anvende ulike anonymiseringsteknikker for {\aa} beskytte de sensitive personopplysningene iboende i dataen. B{\aa}de teoretiske analyser og virkelige hendelser av datainnbrudd har bevist at disse metodene har alvorlige svakheter i hvordan de beskytter individers personopplysninger. Et stort gjennombrudd ble oppn{\aa}dd i 2006 da en metode kalt \textit{differential privacy} ble framlagt som en matematisk garanti for {\aa} beskytte hver rad i et datasett. Siden da har det v{\ae}rt et av fokusene i forskning {\aa} f{\aa} dette konseptet til {\aa} virke i en distribuert omgivelse.

I denne masteroppgaven har vi foresl{\aa}tt et desentralisert rammeverk som lar brukerne gjennomf{\o}re klassifisering etter {\aa} ha aggregert sine lokalt trente modeller, p{\aa} en m{\aa}te som beskytter deres personopplysninger. Vi beskriver en rekke eksperimenter p{\aa} hvordan vi justerte hvert enkelt parameter, og viser hvilken innvirkning dette har p{\aa} avveiningen mellom nytten av resultatet og personvernsniv{\aa}et. Vi har ogs{\aa} sammenlignet v{\aa}r klassifiseringsytelse med andre resultater presentert i forskningslitteraturen og viser at vi har oppn{\aa}dd konkurransedyktige resultater.     

Basert p{\aa} v{\aa}re resultater, har vi produsert et sett med kriterier for hvordan man skal anvende \textit{differential privacy} i en maskinl{\ae}ringsapplikasjon. I tillegg har vi vist til to sektorer i forretningslivet hvor vi ser potensiale for {\aa} skape et 
vellykket system. Vi h{\aa}per at v{\aa}r forskning vil virke banebrytende for distribuerte applikasjoner hvor brukerne beholder kontroll over deres egen data, og kan bruke den for l{\ae}ring uten {\aa} gi fra seg sine personopplysninger.   

\cleardoublepage